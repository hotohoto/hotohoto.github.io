---
title: Latex Cheetsheet
date: 2019-03-05 23:00:00 +09:00
categories:
- ai
layout: post
comments: true
---

MathJax compatible latex references (for my personal uses)

## Greek letters
- $\alpha A$: `\alpha A`
- $\beta B$: `\beta B`
- $\gamma \Gamma$: `\gamma \Gamma`
- $\delta \Delta$: `\delta \Delta`
- $\epsilon \varepsilon E$: `\epsilon \varepsilon E`
- $\zeta Z$: `\zeta Z`
- $\eta H$: `\eta H`
- $\theta \vartheta \Theta$: `\theta \vartheta \Theta`
- $\iota I$: `\iota I`
- $\kappa K$: `\kappa K`
- $\lambda \Lambda$: `\lambda \Lambda`
- $\mu M$: `\mu M`
- $\nu N$: `\nu N`
- $\xi \Xi$: `\xi \Xi`
- $o O$: `o O`
- $\pi \Pi$: `\pi \Pi`
- $\rho \varrho P$: `\rho \varrho P`
- $\sigma \Sigma$: `\sigma \Sigma`
- $\tau T$: `\tau T`
- $\upsilon \Upsilon$: `\upsilon \Upsilon`
- $\phi \varphi \Phi$: `\phi \varphi \Phi`
- $\chi X$: `\chi X`
- $\psi \Psi$: `\psi \Psi`
- $\omega \Omega$: `\omega \Omega`

## Operators
- Binary operators
  - $\times$: `\times`
  - $\otimes \oplus$: `\otimes \oplus`
  - $\cup \cap$: `\cup \cap`
- Relation operators
  - $< >$: `< >`
  - $\subset \supset$: `\subset \supset`
  - $\subseteq \supseteq$: `\subseteq \supseteq`
- Others:
  - $\int \oint \sum \prod$: `\int \oint \sum \prod`

## TODO

- spacing
- brackets and parentheses
- fractions and binomial
- aligning

- Arrays
  - vectors: `\vzero \vone \vmu \vtheta \va \vb \vc \vz`
  - matrices: `\mA \mB \mC \mX \mBeta \mPhi \mLambda \mSigma`
  - tensors: `\tA \tB \tC \tX`
  - random variable: `\reta \ra \rb \rc \rx`
  - random vectors: `\rva \rvb \rvc \rvx`
  - random matrices: `\rmA \rmB \rmC \rmZ`
- Indexing
  - Elements of vectors: `\evalpha_i \evbeta_i \evepsilon_i \evlambda_i \evomega_i \evpsi_i \evsigma_i \evtheta_i \eva_i \evb_i \evc_i \evz_i`
  - Entries of a matrix
    - `\emLambda_{i, j} \emSigma_{i, j} \emA_{i, j} \emB_{i, j} \emC_{i, j} \emX_{i, j}`
  - Entries of a tensor
    - `\etLambda_{i,j,k} \etA_{i,j,k} \etB_{i,j,k} \etC_{i,j,k} \etX_{i,j,k}` :
  - Entries of random matrices
    - `\ermA_{i,j} \ermB_{i,j} \ermC_{i,j} \ermZ_{i,j}`
- Sets and graphs
  - trainset, validset, testset
    - `\train \valid \test`
  - Sets
    - `\sA \sB \sC \sX`
  - Graphs
    - `\gA \gB \gC \gX`

## References
- https://www.overleaf.com/learn


<!--
#### others
* ground truth distribution, empirical distribution defined by training set
    * `\pdata \ptrain \Ptrain` :
$% The true underlying data generating distribution
\newcommand{\pdata}{p_{\rm{data}}}
% The empirical distribution defined by the training set
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
% The model distribution
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
% Stochastic autoencoder distributions
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}
% Laplace distribution
\newcommand{\laplace}{\mathrm{Laplace}}\pdata \ptrain \Ptrain$

* The model distribution
    * `\pmodel \Pmodel \ptildemodel` :
$\pmodel \Pmodel \ptildemodel$

* Stochastic autoencoder distributions; Laplace distribution
    * `\pencode \pdecode \precons \laplace` :
$\pencode \pdecode \precons \laplace$

#### others 2
* `\norm{x}_2` `\diag(\vv)` : $\newcommand\norm[1]{\left\lVert#1\right\rVert}
\newcommand\diag{\text{diag}} \norm{x}_2 \; \diag(\vv)$

| syntax | rendered result | - | syntax | rendered result
|:----------- |---------- | --- |:-----------|----------
| `\E` | $\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
% Wolfram Mathworld says L^2 is for function spaces and \ell^2 is for vectors
% But then they seem to use L^2 for vectors throughout the site, and so does
% wikipedia.
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}
% See usage in notation.tex. Chosen to match Daphne's book.
\newcommand{\parents}{Pa}
% argmax, argmin operators
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
% sign, Trace
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr} \E $ | - | `\standarderror` | $ \standarderror $
| `\Ls` | $ \Ls $ | - | `\Cov` | $ \Cov $
| `\R` | $ \R $ | - | `\normlzero` | $ \normlzero $
| `\emp` | $ \emp $ | - | `\normlone` | $ \normlone $
| `\lr` | $ \lr $ | - | `\normltwo` | $ \normltwo $
| `\reg` | $ \reg $ | - | `\normlp` | $ \normlp $
| `\rect` | $ \rect $ | - | `\normmax` | $ \normmax $
| `\softmax` | $ \softmax $ | - | `\parents` | $ \parents $
| `\sigmoid` | $ \sigmoid $ | - | `\argmax` | $\argmax$
| `\softplus` | $ \softplus $ | - | `\argmin` | $\argmin$
| `\KL` | $ \KL $ | - | `\sign` | $ \sign $
| `\Var` | $ \Var $ | - | `\Tr` | $ \Tr $ -->
